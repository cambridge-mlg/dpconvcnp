from abc import abstractmethod, ABC
from typing import Tuple, Callable, Optional

import tensorflow as tf
import tensorflow_probability as tfp
import gpflow
import numpy as np

from dpconvcnp.data.data import SyntheticGenerator, GroundTruthPredictor
from dpconvcnp.random import randu, zero_mean_mvn
from dpconvcnp.random import Seed
from dpconvcnp.utils import f32, f64, to_tensor, cast

tfd = tfp.distributions


KERNEL_TYPES = [
    "eq",
    "matern12",
    "matern32",
    "matern52",
    "noisy_mixture",
    "weakly_periodic",
]


class GPGenerator(SyntheticGenerator, ABC):
    def __init__(
        self,
        *,
        dim: int,
        **kwargs,
    ):
        super().__init__(**kwargs)

        self.dim = dim

    def sample_outputs(
        self, seed: Seed, x: tf.Tensor
    ) -> Tuple[Seed, tf.Tensor, Callable]:
        """Sample context and target outputs, given the inputs `x`.

        Arguments:
            seed: Random seed.
            x: Tensor of shape (batch_size, num_ctx + num_trg, dim) containing
                the context and target inputs.

        Returns:
            seed: Random seed generated by splitting.
            y: Tensor of shape (batch_size, num_ctx + num_trg, 1) containing
                the context and target outputs.
        """

        # Set up GP kernel
        seed, kernel = self.set_up_kernel(seed=seed)
        gt_pred = self.set_up_ground_truth_gp(kernel=kernel)

        # Set up covariance at input locations
        kxx = kernel(cast(x, f64))

        # Sample from GP with zero mean and covariance kxx
        seed, y = zero_mean_mvn(seed=seed, cov=kxx)
        y = tf.expand_dims(y, axis=-1)

        return seed, cast(y, f32), gt_pred

    @abstractmethod
    def set_up_kernel(self, seed: Seed) -> Tuple[Seed, gpflow.kernels.Kernel]:
        """Set up GP kernel.

        Arguments:
            seed: Random seed.

        Returns:
            seed: Random seed generated by splitting.
            kernel: GP kernel.
        """
        pass

    def set_up_ground_truth_gp(self, kernel: Callable) -> Callable:
        """Set up GP kernel.

        Arguments:
            seed: Random seed.

        Returns:
            seed: Random seed generated by splitting.
            kernel: GP kernel.
        """
        return GPGroundTruthPredictor(kernel=kernel)


class RandomScaleGPGenerator(GPGenerator):
    noisy_mixture_long_lengthscale: float = 1.0
    weakly_periodic_period: float = 0.25

    def __init__(
        self,
        *,
        kernel_type: str,
        min_log10_lengthscale: float,
        max_log10_lengthscale: float,
        min_log10_noise_std: Optional[float] = None,
        max_log10_noise_std: Optional[float] = None,
        noise_std: Optional[float] = None,
        **kwargs,
    ):
        super().__init__(**kwargs)

        if noise_std is not None:
            min_log10_noise_std = np.log10(noise_std)
            max_log10_noise_std = np.log10(noise_std)

        self.kernel_type = kernel_type
        self.min_log10_lengthscale = to_tensor(min_log10_lengthscale, f64)
        self.max_log10_lengthscale = to_tensor(max_log10_lengthscale, f64)
        self.min_log10_noise_std = to_tensor(min_log10_noise_std, f64)
        self.max_log10_noise_std = to_tensor(max_log10_noise_std, f64)

        assert (
            self.kernel_type in KERNEL_TYPES
        ), f"kernel_type must be in {KERNEL_TYPES}, found {self.kernel_type=}."

    def set_up_kernel(self, seed: Seed) -> Tuple[Seed, gpflow.kernels.Kernel]:
        # Sample lengthscale
        seed, log10_lengthscale = randu(
            shape=(),
            seed=seed,
            minval=self.min_log10_lengthscale,
            maxval=self.max_log10_lengthscale,
        )
        lengthscale = 10.0**log10_lengthscale

        # Sample noise_std
        seed, log10_noise_std = randu(
            shape=(),
            seed=seed,
            minval=self.min_log10_noise_std,
            maxval=self.max_log10_noise_std,
        )
        noise_std = 10.0**log10_noise_std

        if self.kernel_type == "eq":
            kernel = gpflow.kernels.SquaredExponential(
                lengthscales=lengthscale
            )

        elif self.kernel_type == "matern12":
            kernel = gpflow.kernels.Matern12(lengthscales=lengthscale)

        elif self.kernel_type == "matern32":
            kernel = gpflow.kernels.Matern32(lengthscales=lengthscale)

        elif self.kernel_type == "matern52":
            kernel = gpflow.kernels.Matern52(lengthscales=lengthscale)

        elif self.kernel_type == "noisy_mixture":
            kernel = gpflow.kernels.SquaredExponential(
                lengthscales=lengthscale,
            ) + gpflow.kernels.SquaredExponential(
                lengthscales=self.noisy_mixture_long_lengthscale,
            )

        elif self.kernel_type == "weakly_periodic":
            kernel = gpflow.kernels.SquaredExponential(
                lengthscales=lengthscale,
            ) * gpflow.kernels.Periodic(
                period=self.weakly_periodic_period,
            )

        kernel = kernel + gpflow.kernels.White(
            variance=noise_std**2.0,
        )

        return seed, kernel


class GPGroundTruthPredictor(GroundTruthPredictor):
    def __init__(self, kernel: Callable):
        self.kernel = kernel

    def __call__(
        self,
        x_ctx: tf.Tensor,
        y_ctx: tf.Tensor,
        x_trg: tf.Tensor,
        y_trg: Optional[tf.Tensor] = None,
    ) -> Tuple[tf.Tensor, tf.Tensor, Optional[tf.Tensor]]:
        dtype = x_ctx.dtype

        x_ctx = cast(x_ctx, f64)
        y_ctx = cast(y_ctx, f64)
        x_trg = cast(x_trg, f64)
        num_ctx = x_ctx.shape[1]

        k = self.kernel(tf.concat([x_ctx, x_trg], axis=1))
        kcc = k[:, :num_ctx, :num_ctx]
        kct = k[:, :num_ctx, num_ctx:]
        ktc = k[:, num_ctx:, :num_ctx]
        ktt = k[:, num_ctx:, num_ctx:]

        mean = tf.matmul(ktc, tf.linalg.solve(kcc, y_ctx))[:, :, 0]
        cov = ktt - tf.matmul(ktc, tf.linalg.solve(kcc, kct))
        std = tf.sqrt(tf.linalg.diag_part(cov))

        if y_trg is not None:
            y_trg = cast(y_trg, f64)
            gt_log_lik = tfd.Normal(loc=mean, scale=std).log_prob(
                y_trg[:, :, 0]
            )
            gt_log_lik = tf.reduce_sum(gt_log_lik, axis=1)
            gt_log_lik = cast(gt_log_lik, dtype)

        else:
            gt_log_lik = None

        mean = cast(mean, dtype)[:, :, None]
        std = cast(std, dtype)[:, :, None]

        return mean, std, gt_log_lik
